{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import useful_functions as f\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a user agent string\n",
    "user_agent = 'MandarineCorp (louis.brun@epfl.ch)'\n",
    "\n",
    "# Specify the headers with the user agent\n",
    "headers = {\n",
    "    'User-Agent': user_agent,\n",
    "    'accept': 'application/json'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RETRIEVE LIST OF PHILOSOPHIES IN **ENGLISH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET THE PHILOSOPHIES FROM THE PAGE : List of philosophies\n",
    "\n",
    "# Specify the API endpoint URL\n",
    "api_url = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "# Specify the parameters for the API request\n",
    "params = {\n",
    "    'action': 'query',\n",
    "    'prop': 'revisions',\n",
    "    'titles': 'List_of_philosophies',\n",
    "    'rvslots': '*',\n",
    "    'rvprop': 'content',\n",
    "    'formatversion': 2,\n",
    "    'format': 'json'\n",
    "}\n",
    "\n",
    "# API request\n",
    "response = requests.get(api_url, params=params)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "\n",
    "    # Extract the content of the first revision\n",
    "    revisions = data['query']['pages'][0]['revisions']\n",
    "    \n",
    "    if revisions:\n",
    "        content = revisions[0]['slots']['main']['content']\n",
    "        \n",
    "        # Use a regular expression to find section titles\n",
    "        section_titles = re.findall(r'\\[\\[([^|\\]]+)(?:\\|[^]]+)?\\]\\]', content)\n",
    "        \n",
    "        while section_titles[0][0]!='A' or section_titles[-1][0]!='Z':\n",
    "            if section_titles[0][0]!='A':\n",
    "                section_titles.pop(0)\n",
    "            if section_titles[-1][0]!='Z':\n",
    "                section_titles.pop(-1)\n",
    "\n",
    "        #print(section_titles)\n",
    "    else:\n",
    "        print(\"No content found.\")\n",
    "else:\n",
    "    # Print an error message if the request was unsuccessful\n",
    "    print(f\"Error: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/section_titles.npy', section_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATAFRAME OF PHILOSOPHIES IN ENGLISH AND VIEWS (1 COLUMN ARTICLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 404\n",
      "Nonduality (spirituality)\n"
     ]
    }
   ],
   "source": [
    "philo_views_en=pd.DataFrame()\n",
    "\n",
    "#PAGEVIEWS \n",
    "for page_title in section_titles: \n",
    "    # URL for the Wikimedia Pagecounts API to get the number of views for a page\n",
    "    url = f'https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/en.wikipedia.org/all-access/all-agents/{page_title}/daily/2019010100/2022010100'\n",
    "\n",
    "    # Define a user agent to have acces to the API \n",
    "    user_agent = 'MandarineCorp (louis.brun@epfl.ch)'\n",
    "\n",
    "    # Specify the headers with the user agent\n",
    "    headers = {\n",
    "        'User-Agent': user_agent,\n",
    "        'accept': 'application/json'\n",
    "    }\n",
    "\n",
    "    # Making a GET request\n",
    "    response_views = requests.get(url,headers=headers)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response_views.status_code == 200:\n",
    "        # Print the response content\n",
    "        data = response_views.json()\n",
    "    else:\n",
    "        # Print an error message if the request was unsuccessful\n",
    "        print(f\"Error: {response_views.status_code}\")\n",
    "        print(page_title)\n",
    "\n",
    "\n",
    "    # Extract the 'items' list from the data\n",
    "    items_list = data['items']\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(items_list)\n",
    "    philo_views_en = pd.concat([philo_views_en,df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(philo_views_en)\n",
    "columns_to_remove = ['granularity','access','agent']\n",
    "philo_views_en.drop(columns=columns_to_remove,axis=1,inplace=True)\n",
    "philo_views_en.to_csv('data/Philo_en.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the views for the diffrent languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_list(target_languages, page_titles):\n",
    "    api_url = \"https://en.wikipedia.org/w/api.php\"\n",
    "    language_links = []\n",
    "\n",
    "    for page in page_titles : \n",
    "\n",
    "    # Make separate requests for each language\n",
    "        for lang in target_languages:\n",
    "            params = {\n",
    "                'action': 'query',\n",
    "                'titles': page,\n",
    "                'prop': 'langlinks',\n",
    "                'llprop': 'url',\n",
    "                'format': 'json',\n",
    "                'lllang': lang,\n",
    "            }\n",
    "\n",
    "            # Make the API request\n",
    "            response = requests.get(api_url, params=params)\n",
    "            data = response.json()\n",
    "\n",
    "            # Check if the request was successful (status code 200)\n",
    "            if response.status_code == 200:\n",
    "                # Extract language links from the API response\n",
    "                pages = data['query']['pages']\n",
    "                page_id = next(iter(pages))\n",
    "                langlinks = pages[page_id].get('langlinks', [])\n",
    "                for link in langlinks:\n",
    "                    language_links.append( [link['url'],page])\n",
    "            else:\n",
    "                print(f\"Error for language {lang}: {response.status_code}\")\n",
    "    return language_links\n",
    "        \n",
    "\n",
    "def get_page_views_by_languages(links,page_titles):\n",
    "    philo_views=pd.DataFrame()\n",
    "\n",
    "    for link in links:\n",
    "        # Define a user agent to have acces to the API \n",
    "        user_agent = 'MandarineCorp (clementine.naim@epfl.ch)'\n",
    "        # Specify the headers with the user agent\n",
    "        headers = {\n",
    "            'User-Agent': user_agent,\n",
    "            'accept': 'application/json'\n",
    "        \n",
    "        }\n",
    "        # Find country code:\n",
    "        code = urlsplit(link[0]).hostname.split('.')[0]\n",
    "\n",
    "        path = unquote(urlsplit(link[0]).path)\n",
    "        # Use a regular expression to find the title part\n",
    "        match = re.search(r'/wiki/(.+)', path)\n",
    "        title = match.group(1)\n",
    "        subject=link[1]\n",
    "\n",
    "        #print(link,title,code,subject)\n",
    "        url = f'https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/{code}.wikipedia.org/all-access/all-agents/{title}/daily/2019010100/2022010100'\n",
    "        # Making a GET request\n",
    "        response_views = requests.get(url,headers=headers)\n",
    "\n",
    "        # Check if the request was successful (status code 200)\n",
    "        if response_views.status_code == 200:\n",
    "            # Print the response content\n",
    "            data = response_views.json()\n",
    "            # Extract the 'items' list from the data\n",
    "            items_list = data['items']\n",
    "            #print(items_list)\n",
    "            # Create a DataFrame\n",
    "            df = pd.DataFrame(items_list)\n",
    "            df[\"subject\"]=subject\n",
    "            df[\"code\"] =code\n",
    "            #print(df)\n",
    "            philo_views = pd.concat([philo_views,df])\n",
    "        else:\n",
    "            #Print an error message if the request was unsuccessful\n",
    "            print(f\"Error: {response_views.status_code}\")\n",
    "            print(title)\n",
    "\n",
    "\n",
    "        #i+=1\n",
    "        #if i==11 :\n",
    "        #    index_subject+=1\n",
    "        #    i=0\n",
    "    return philo_views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_languages = ['fr', 'ja', 'de', 'it','da','nl','no','sr','sv','ko','fi'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_links = get_url_list(target_languages,section_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/languages_links.npy', language_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_titles=np.load('data/section_titles.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_links =np.load('data/languages_links.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 404\n",
      "Philosophie_des_Absurden\n",
      "Error: 404\n",
      "実在論的観念論\n",
      "Error: 404\n",
      "美的現実主義\n",
      "Error: 404\n",
      "アフリカーナ哲学\n",
      "Error: 404\n",
      "Afrocentrism\n",
      "Error: 404\n",
      "Antinatalisme\n",
      "Error: 404\n",
      "Monisme_anomal\n",
      "Error: 404\n",
      "Averoizam\n",
      "Error: 404\n",
      "Avicennismo\n",
      "Error: 404\n",
      "아비센나주의\n",
      "Error: 404\n",
      "Biosophie\n",
      "Error: 404\n",
      "新プラトン主義とキリスト教\n",
      "Error: 404\n",
      "Philosophie_des_Zufalls\n",
      "Error: 404\n",
      "キリスト教実存主義\n",
      "Error: 404\n",
      "기독교적_실존주의\n",
      "Error: 404\n",
      "認知主義\n",
      "Error: 404\n",
      "Communautarisme_(concept_politique)\n",
      "Error: 404\n",
      "Holisme_de_confirmation\n",
      "Error: 404\n",
      "Kosmisk_skräck\n",
      "Error: 404\n",
      "Negazionismo_scientifico\n",
      "Error: 404\n",
      "의무론\n",
      "Error: 404\n",
      "제거적_유물론\n",
      "Error: 404\n",
      "情緒主義\n",
      "Error: 404\n",
      "Vestlig_esoterik\n",
      "Error: 404\n",
      "Њемачки_идеализам\n",
      "Error: 404\n",
      "Istoricizam\n",
      "Error: 404\n",
      "Umanesimo_(filosofia)\n",
      "Error: 404\n",
      "Illuminazionismo\n",
      "Error: 404\n",
      "Logica_informale\n",
      "Error: 404\n",
      "Persisk_filosofi\n",
      "Error: 404\n",
      "Irrealismi\n",
      "Error: 404\n",
      "カント主義\n",
      "Error: 404\n",
      "Logica_informale\n",
      "Error: 404\n",
      "Philosophie_der_Logik\n",
      "Error: 404\n",
      "道徳的相対主義\n",
      "Error: 404\n",
      "Uusluddismi\n",
      "Error: 404\n",
      "新ピタゴラス主義\n",
      "Error: 404\n",
      "New_thought\n",
      "Error: 404\n",
      "Нова_мисао\n",
      "Error: 404\n",
      "非認知主義\n",
      "Error: 404\n",
      "열린_개인주의\n",
      "Error: 404\n",
      "Perenn_filosofi\n",
      "Error: 404\n",
      "관점주의\n",
      "Error: 404\n",
      "Realismo_platonico\n",
      "Error: 404\n",
      "Postpositivismi\n",
      "Error: 404\n",
      "Progressivitet\n",
      "Error: 404\n",
      "Pytagoreer\n",
      "Error: 404\n",
      "정적주의\n",
      "Error: 404\n",
      "Den_raëlske_bevegelse\n",
      "Error: 404\n",
      "라엘교\n",
      "Error: 404\n",
      "연관_논리\n",
      "Error: 404\n",
      "러시아_철학\n",
      "Error: 404\n",
      "특이점주의\n",
      "Error: 404\n",
      "Scetticismo_(filosofia)\n",
      "Error: 404\n",
      "Spiritualisme\n",
      "Error: 404\n",
      "Philosophie_du_sport\n",
      "Error: 404\n",
      "Filosofia_dello_sport\n",
      "Error: 404\n",
      "Korvausteologia\n",
      "Error: 404\n",
      "Theosophie_(Blavatsky)\n",
      "Error: 404\n",
      "Трансцендентна_теозофија\n",
      "Error: 404\n",
      "Transcendentalizam\n",
      "Error: 404\n",
      "Värdepluralism\n",
      "Error: 404\n",
      "Philosophie_de_la_guerre\n"
     ]
    }
   ],
   "source": [
    "Views_all_lang=get_page_views_by_languages(language_links,section_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['granularity', 'access', 'agent'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m columns_to_remove \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgranularity\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccess\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124magent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m \u001b[43mViews_all_lang\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns_to_remove\u001b[49m\u001b[43m,\u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m Views_all_lang\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/Philos_lang.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/core/frame.py:5347\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5200\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5201\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5208\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5211\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5212\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5345\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5346\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5349\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5353\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5354\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5355\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/core/generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4711\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/core/generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4751\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4753\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4754\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4756\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/core/indexes/base.py:6992\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6991\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6992\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6993\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6994\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['granularity', 'access', 'agent'] not found in axis\""
     ]
    }
   ],
   "source": [
    "columns_to_remove = ['granularity','access','agent']\n",
    "Views_all_lang.drop(columns=columns_to_remove,inplace=True)\n",
    "Views_all_lang.to_csv('data/Philos_lang.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DETERMINE BROADER TOPICS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select only articles in all languages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "philo_lang=pd.read_csv('data/Philos_lang.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_counts = philo_lang.groupby('subject')['code'].nunique()\n",
    "articles_to_keep = article_counts[article_counts == philo_lang['code'].nunique()].index.tolist()\n",
    "views_lang_filtered = philo_lang[philo_lang['subject'].isin(articles_to_keep)]\n",
    "views_lang_filtered.to_csv('data/Philos_lang.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Philo_en.csv')\n",
    "df_pivoted = df.pivot_table(index='timestamp'   ,columns='article', values='views')\n",
    "\n",
    "total_views_per_date = df.groupby('timestamp')['views'].sum()\n",
    "# Merge the total views per date back to the original DataFrame\n",
    "df_pivoted['ViewsTotal']=total_views_per_date\n",
    "\n",
    "df_pivoted.head(10)\n",
    "df_reg_en = df_pivoted.fillna(0)\n",
    "df_reg_en.columns = df_reg_en.columns.str.replace('_', ' ')\n",
    "df_reg_en.rename(columns={\"'Pataphysics\":'Pataphysics'}, inplace=True)\n",
    "final_df = df_reg_en[articles_to_keep]\n",
    "final_df.to_csv('data/df_en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1097, 108)\n",
      "(1097, 108)\n",
      "(1097, 108)\n",
      "(1097, 108)\n",
      "(1097, 108)\n",
      "(1097, 108)\n",
      "(1097, 108)\n",
      "(1097, 108)\n",
      "(1097, 108)\n",
      "(1097, 108)\n",
      "(1097, 108)\n"
     ]
    }
   ],
   "source": [
    "df_en = pd.read_csv('data/df_en.csv')\n",
    "target_languages = ['fr', 'ja', 'de', 'it','da','nl','no','sr','sv','ko','fi'] \n",
    "\n",
    "for lang in target_languages:\n",
    "    df_piv = philo_lang[philo_lang['code']==lang].pivot_table(index='timestamp',columns='subject', values='views')\n",
    "\n",
    "    total_views_per_date = philo_lang[philo_lang['code']==lang].groupby('timestamp')['views'].sum()\n",
    "    # Merge the total views per date back to the original DataFrame\n",
    "    df_piv['ViewsTotal']=total_views_per_date\n",
    "    \n",
    "\n",
    "    # Identify missing columns in each DataFrame\n",
    "    missing_cols= df_en.columns.difference(df_piv.columns)\n",
    "\n",
    "    # Add missing columns with NaN values\n",
    "    df_piv = pd.concat([df_piv, pd.DataFrame(columns=missing_cols)], axis=1)\n",
    "\n",
    "    # Reorder columns while keeping values in the correct order\n",
    "    df_piv = df_piv.loc[:, df_en.columns]\n",
    "    df_piv.drop(columns='timestamp',inplace=True)\n",
    "\n",
    "\n",
    "    df_reg = df_piv.fillna(0) \n",
    "    df_reg.drop(columns=df_reg.columns[0])\n",
    "    df_reg.rename(columns={\"'Pataphysics\":'Pataphysics'},inplace=True)\n",
    "    filepath = 'data/df_'+lang+'.csv'\n",
    "    df_reg.to_csv(filepath,index='False')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>Aesthetics</th>\n",
       "      <th>Agnosticism</th>\n",
       "      <th>Analytic philosophy</th>\n",
       "      <th>Anarchism</th>\n",
       "      <th>Anarchy</th>\n",
       "      <th>Animism</th>\n",
       "      <th>Asceticism</th>\n",
       "      <th>Atheism</th>\n",
       "      <th>Authoritarianism</th>\n",
       "      <th>...</th>\n",
       "      <th>Teleology</th>\n",
       "      <th>Theism</th>\n",
       "      <th>Theology</th>\n",
       "      <th>Thomism</th>\n",
       "      <th>Transhumanism</th>\n",
       "      <th>Utilitarianism</th>\n",
       "      <th>Vienna Circle</th>\n",
       "      <th>Vitalism</th>\n",
       "      <th>Zen</th>\n",
       "      <th>Zoroastrianism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019010100</td>\n",
       "      <td>1736.0</td>\n",
       "      <td>3413.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>1495.0</td>\n",
       "      <td>1385.0</td>\n",
       "      <td>1301.0</td>\n",
       "      <td>2696.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>...</td>\n",
       "      <td>697.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>951.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>942.0</td>\n",
       "      <td>1451.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>1805.0</td>\n",
       "      <td>9866.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019010200</td>\n",
       "      <td>1926.0</td>\n",
       "      <td>3801.0</td>\n",
       "      <td>677.0</td>\n",
       "      <td>2074.0</td>\n",
       "      <td>1691.0</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>3069.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>...</td>\n",
       "      <td>855.0</td>\n",
       "      <td>767.0</td>\n",
       "      <td>1146.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>1153.0</td>\n",
       "      <td>1898.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>495.0</td>\n",
       "      <td>1894.0</td>\n",
       "      <td>9525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019010300</td>\n",
       "      <td>1898.0</td>\n",
       "      <td>3493.0</td>\n",
       "      <td>688.0</td>\n",
       "      <td>2132.0</td>\n",
       "      <td>1583.0</td>\n",
       "      <td>1529.0</td>\n",
       "      <td>1469.0</td>\n",
       "      <td>3094.0</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>...</td>\n",
       "      <td>777.0</td>\n",
       "      <td>782.0</td>\n",
       "      <td>1188.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>1797.0</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>719.0</td>\n",
       "      <td>1840.0</td>\n",
       "      <td>8196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019010400</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>3655.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>1442.0</td>\n",
       "      <td>1602.0</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>2991.0</td>\n",
       "      <td>1389.0</td>\n",
       "      <td>...</td>\n",
       "      <td>817.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>1229.0</td>\n",
       "      <td>1928.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>1886.0</td>\n",
       "      <td>8294.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019010500</td>\n",
       "      <td>1739.0</td>\n",
       "      <td>3423.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>2348.0</td>\n",
       "      <td>1148.0</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>1334.0</td>\n",
       "      <td>2894.0</td>\n",
       "      <td>1259.0</td>\n",
       "      <td>...</td>\n",
       "      <td>777.0</td>\n",
       "      <td>773.0</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>1209.0</td>\n",
       "      <td>1805.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>1904.0</td>\n",
       "      <td>9097.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>2021122800</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>2473.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>2322.0</td>\n",
       "      <td>915.0</td>\n",
       "      <td>1579.0</td>\n",
       "      <td>1845.0</td>\n",
       "      <td>2416.0</td>\n",
       "      <td>1313.0</td>\n",
       "      <td>...</td>\n",
       "      <td>607.0</td>\n",
       "      <td>629.0</td>\n",
       "      <td>1534.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>1699.0</td>\n",
       "      <td>1902.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>1549.0</td>\n",
       "      <td>5874.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>2021122900</td>\n",
       "      <td>1917.0</td>\n",
       "      <td>3152.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>2369.0</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1686.0</td>\n",
       "      <td>1483.0</td>\n",
       "      <td>2472.0</td>\n",
       "      <td>1734.0</td>\n",
       "      <td>...</td>\n",
       "      <td>579.0</td>\n",
       "      <td>538.0</td>\n",
       "      <td>1352.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>1818.0</td>\n",
       "      <td>1828.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>5841.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>2021123000</td>\n",
       "      <td>1782.0</td>\n",
       "      <td>2683.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>2289.0</td>\n",
       "      <td>965.0</td>\n",
       "      <td>2353.0</td>\n",
       "      <td>1702.0</td>\n",
       "      <td>2340.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>...</td>\n",
       "      <td>581.0</td>\n",
       "      <td>656.0</td>\n",
       "      <td>1144.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>1714.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>1477.0</td>\n",
       "      <td>5633.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>2021123100</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>2474.0</td>\n",
       "      <td>671.0</td>\n",
       "      <td>2055.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>1682.0</td>\n",
       "      <td>1319.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>1377.0</td>\n",
       "      <td>...</td>\n",
       "      <td>568.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>853.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>1732.0</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>5046.0</td>\n",
       "      <td>5803.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>2022010100</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>2686.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>2168.0</td>\n",
       "      <td>830.0</td>\n",
       "      <td>1737.0</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>2451.0</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>...</td>\n",
       "      <td>532.0</td>\n",
       "      <td>646.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>1514.0</td>\n",
       "      <td>1324.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>1645.0</td>\n",
       "      <td>5834.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1097 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp  Aesthetics  Agnosticism  Analytic philosophy  Anarchism  \\\n",
       "0     2019010100      1736.0       3413.0                684.0     1820.0   \n",
       "1     2019010200      1926.0       3801.0                677.0     2074.0   \n",
       "2     2019010300      1898.0       3493.0                688.0     2132.0   \n",
       "3     2019010400      1989.0       3655.0                711.0     1969.0   \n",
       "4     2019010500      1739.0       3423.0                697.0     2348.0   \n",
       "...          ...         ...          ...                  ...        ...   \n",
       "1092  2021122800      1950.0       2473.0                655.0     2322.0   \n",
       "1093  2021122900      1917.0       3152.0                635.0     2369.0   \n",
       "1094  2021123000      1782.0       2683.0                608.0     2289.0   \n",
       "1095  2021123100      1518.0       2474.0                671.0     2055.0   \n",
       "1096  2022010100      1620.0       2686.0                662.0     2168.0   \n",
       "\n",
       "      Anarchy  Animism  Asceticism  Atheism  Authoritarianism  ...  Teleology  \\\n",
       "0      1495.0   1385.0      1301.0   2696.0             937.0  ...      697.0   \n",
       "1      1691.0   1498.0      1508.0   3069.0            1156.0  ...      855.0   \n",
       "2      1583.0   1529.0      1469.0   3094.0            1408.0  ...      777.0   \n",
       "3      1442.0   1602.0      1368.0   2991.0            1389.0  ...      817.0   \n",
       "4      1148.0   1460.0      1334.0   2894.0            1259.0  ...      777.0   \n",
       "...       ...      ...         ...      ...               ...  ...        ...   \n",
       "1092    915.0   1579.0      1845.0   2416.0            1313.0  ...      607.0   \n",
       "1093    910.0   1686.0      1483.0   2472.0            1734.0  ...      579.0   \n",
       "1094    965.0   2353.0      1702.0   2340.0            1643.0  ...      581.0   \n",
       "1095    785.0   1682.0      1319.0   2306.0            1377.0  ...      568.0   \n",
       "1096    830.0   1737.0      1329.0   2451.0            1454.0  ...      532.0   \n",
       "\n",
       "      Theism  Theology  Thomism  Transhumanism  Utilitarianism  Vienna Circle  \\\n",
       "0      636.0     951.0    343.0          942.0          1451.0          177.0   \n",
       "1      767.0    1146.0    392.0         1153.0          1898.0          206.0   \n",
       "2      782.0    1188.0    359.0         1797.0          2050.0          206.0   \n",
       "3      800.0    1205.0    336.0         1229.0          1928.0          201.0   \n",
       "4      773.0    1101.0    341.0         1209.0          1805.0          200.0   \n",
       "...      ...       ...      ...            ...             ...            ...   \n",
       "1092   629.0    1534.0    319.0         1699.0          1902.0          201.0   \n",
       "1093   538.0    1352.0    314.0         1818.0          1828.0          196.0   \n",
       "1094   656.0    1144.0    370.0         1984.0          1714.0          205.0   \n",
       "1095   581.0     853.0    349.0         1732.0          1540.0          163.0   \n",
       "1096   646.0     886.0    320.0         1514.0          1324.0          163.0   \n",
       "\n",
       "      Vitalism     Zen  Zoroastrianism  \n",
       "0        366.0  1805.0          9866.0  \n",
       "1        495.0  1894.0          9525.0  \n",
       "2        719.0  1840.0          8196.0  \n",
       "3        446.0  1886.0          8294.0  \n",
       "4        458.0  1904.0          9097.0  \n",
       "...        ...     ...             ...  \n",
       "1092     408.0  1549.0          5874.0  \n",
       "1093     414.0  1470.0          5841.0  \n",
       "1094     339.0  1477.0          5633.0  \n",
       "1095     355.0  5046.0          5803.0  \n",
       "1096     334.0  1645.0          5834.0  \n",
       "\n",
       "[1097 rows x 109 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
